{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has always been an inherent bias between White and non-White establishments in the context of what makes something trustworthy. Especially during this turbulent time, it's important to review our actions and learn from our past mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name & Github\n",
    "\n",
    "- Name: Alexa Acosta\n",
    "- GitHub Username: A12870957"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am aiming to question whether a restaurant at a certain area code is likelier to be considered a critical risk than those from a different area code, dependent on the population of non-Whites in the area.\n",
    "By examining this relationship, we can see if implicit and explicit bias does negatively impact restaurants that do not deserve such harsh criticisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I don't have background or prior work, because I got a bit too stressed with reading this week.\n",
    "Thus, I'm only leaning upon my own experiences with implicit bias (coming from within my own family and my upbringing) after being exposed to a radically different culture during my formative years (from the Philippines to the U.S. at age 13) and explicit bias (experienced and observed by myself and my own close friends).\n",
    "\n",
    "Additionally, it's hard to ignore something as important as bias (racism) when its impact is so enormous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hypothesize that the mean value of critical risks are higher in predominantly non-White areas than it is in predominantly White areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: inspections\n",
    "- Link to the dataset: 'data/inspections.csv'\n",
    "- Number of observations: 18466\n",
    "\n",
    "This CSV contains information for a single inspection done on a specific establishment. It includes basic information like the date of inspection, any comments the inspector suggested, the inspector and their ID, as well as information on how critical/severe any problems are, the number of problems found, and statistics to refer to previous inspections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: violations\n",
    "- Link to the dataset: 'data/inspections.csv'\n",
    "- Number of observations: 189802\n",
    "\n",
    "Information associated with a single violation found within a restaurant. It's basically an expanded version of the violations found during inspection in inspections.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: yelp\n",
    "- Link to the dataset: 'data/inspections.csv'\n",
    "- Number of observations: 3688\n",
    "\n",
    "Details of restaurants that have Yelp! reviews associated with them, including ratings and how many people have given reviews. It will be helpful with showing a more subjective review of a restaurant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: zipcodes\n",
    "- Link to the dataset: 'data/inspections.csv'\n",
    "- Number of observations: 38\n",
    "\n",
    "Details information about the associated incomes (hollistic) of the people in the area, as well as the percentage of non-Whites in the area. This will be helpful in determining whether restaurants in the same area reflect the quality of life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspections and violations are easily connected with the unique 'hsisid' property. yelp will get connected with the 'x' and 'y' values ('longitude' and 'latitude'). zipcodes will be used separately, as most of its data deals with a larger, general area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I require this setup to properly utilize DataFrames, models and plots, and testing once the data was cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also reading in the CSV files from the 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections = pd.read_csv('data/inspections.csv')\n",
    "violations = pd.read_csv('data/violations.csv')\n",
    "yelp = pd.read_csv('data/yelp.csv')\n",
    "zipcodes = pd.read_csv('data/zipcodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I have created simple standardizing methods for easier parsing.\n",
    "- I'm scrubbing a lot of the identifiable information (except 'x' and 'y' or 'longitude' and 'latitude' for use in connecting the dataframes with each other) since I'm primarily concerned with the geographic information and population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_hsisid(hsisid):\n",
    "    return int(str(hsisid)[4:])\n",
    "\n",
    "def standardize_zip(code):\n",
    "    code = str(code)\n",
    "    if code.find('-') == -1:\n",
    "        return int(code)\n",
    "    return int(code[0:code.find('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_ins = ['date', 'name', 'address1', 'address2', 'city', 'state',\n",
    "       'postalcode', 'phonenumber', 'restaurantopendate', 'critical',\n",
    "       'days_from_open_date', 'facilitytype', 'x', 'y', 'geocodestatus',\n",
    "       'type', 'description', 'inspectedby', 'inspection_num', 'inspector_id',\n",
    "       'previous_inspection_date', 'days_since_previous_inspection',\n",
    "       'previous_inspection_by_same_inspector', 'top_match', 'second_match',\n",
    "       'num_critical_previous','num_non_critical_previous','num_critical_mean_previous','num_non_critical_mean_previous',\n",
    "       'avg_neighbor_num_critical','avg_neighbor_num_non_critical']\n",
    "\n",
    "inspections_smaller = inspections.drop(columns=to_drop_ins,axis='columns')\n",
    "inspections_smaller['hsisid'] = inspections_smaller['hsisid'].apply(standardize_hsisid)\n",
    "inspections_smaller['zip'] = inspections_smaller['zip'].apply(standardize_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_vio = ['X.objectid', 'inspectdate', 'category', 'statecode',\n",
    "       'questionno', 'violationcode', 'shortdesc', 'count',\n",
    "       'inspectedby', 'comments', 'observationtype', 'cdcdataitem']\n",
    "\n",
    "violations_smaller = violations.drop(columns=to_drop_vio,axis='columns')\n",
    "violations_smaller['hsisid'] = violations_smaller['hsisid'].apply(standardize_hsisid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_yelp = ['id', 'name', 'is_closed', 'address1',\n",
    "       'latitude', 'longitude', 'phone', 'hotdogs', 'longitude', 'latitude',\n",
    "       'sandwiches', 'pizza', 'tradamerican', 'burgers', 'mexican', 'grocery',\n",
    "       'breakfast_brunch', 'coffee', 'chinese', 'italian', 'newamerican',\n",
    "       'chicken_wings', 'delis', 'bars', 'salad', 'seafood', 'bbq', 'bakeries',\n",
    "       'sushi']\n",
    "\n",
    "yelp_smaller = yelp.drop(columns=to_drop_yelp,axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm creating a hollistic DataFrame object that holds all of the unique observations (restaurants) and its associated inspections and violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = violations_smaller.merge(inspections_smaller, on='hsisid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took out the mean, min and max values of the critical violations grouped by zip code. I also calculated the mean of the scores given by the inspectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_critical = df.groupby('zip')['num_critical'].mean()\n",
    "min_critical = df.groupby('zip')['num_critical'].min()\n",
    "max_critical = df.groupby('zip')['num_critical'].max()\n",
    "\n",
    "mean_ncritical = df.groupby('zip')['num_non_critical'].mean()\n",
    "min_ncritical = df.groupby('zip')['num_non_critical'].min()\n",
    "max_ncritical = df.groupby('zip')['num_non_critical'].max()\n",
    "\n",
    "scores = df.groupby('zip')['score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I proceed to create a model between critical violations by area code against percentage of non-Whites by area code. I also do the same for non-critical violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the models will give a visual on the effects of non-White percentage per area code on critical and non-critical violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the models with a two-tailed t-test in order to give a more concrete view on how effective non-White percentage per area code is on violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have scrubbed sensitive identifying information according to the Safe Harbor method. Unfortunately, I had to retain information about a restaurant's zip/postal code as it is vital to the question at hand.\n",
    "\n",
    "While zip codes are allowed to be used when there are more than 20,000 people living within the area, I have no way to confirm that the zip codes had more than 20,000 people within in. Thus, I cannot guarantee full anonymity of the information of the restaurants gathered with the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There would be a discussion here, if I finished this one time. Unfortunately I did not.\n",
    "\n",
    "If I had to make a guesstimation, predominantly non-White establishments per area code may have more critical violations, as well as lower Yelp! ratings than other establishments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
